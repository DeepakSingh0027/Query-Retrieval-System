# ğŸ“„ Query Retrieval System

A powerful **multi-format document question-answering system** that extracts, processes, and searches through various document types to provide contextually accurate answers using **semantic search** and **LLMs**.

## ğŸš€ Overview

This system takes **documents** (via URL or file), processes them through a **smart extraction pipeline** (with OCR for scanned content), splits the content into semantic chunks, embeds them into vectors, and retrieves the most relevant chunks for a given question.  
It then sends the context to an **LLM (GPT-4.1/GPT-5.1)** to produce accurate, document-based answers.

## âœ¨ Key Features

- **Multi-format Support**: PDF, DOCX, PPTX, XLSX, ZIP archives, and images.
- **Smart Extraction Pipeline**:
  - MIME type detection
  - Format-specific extractors
  - OCR for scanned documents & images
  - Fallback conversion for unknown formats
- **Parallel Processing**:
  - Concurrent document extraction
  - Parallel question processing
- **Semantic Search**:
  - Embedding-based similarity search
  - Retrieves relevant chunks even without exact keyword matches
- **Scalable LLM Integration**:
  - Key rotation for LLM API calls
  - JSON-formatted output for easy parsing

## ğŸ› ï¸ Tech Stack

- **Backend**: Node.js + Express
- **AI / ML**:
  - [Xenova Transformers](https://github.com/xenova/transformers.js) â€“ Embedding generation
  - [GPT-4.1 via GitHub Models API](https://docs.github.com/en/ai) â€“ Answer generation
- **OCR**: [Tesseract.js](https://tesseract.projectnaptha.com/)
- **Document Extraction**:
  - [pdf-parse](https://www.npmjs.com/package/pdf-parse) â€“ PDF text extraction
  - [mammoth](https://github.com/mwilliamson/mammoth.js) â€“ DOCX text extraction
  - [unzipit](https://www.npmjs.com/package/unzipit) â€“ PPTX/DOCX XML parsing
  - [xlsx](https://www.npmjs.com/package/xlsx) â€“ Excel parsing
  - [libreoffice-convert](https://www.npmjs.com/package/libreoffice-convert) â€“ Format conversion
- **Utilities**:
  - axios, fs-extra, uuid, file-type, p-limit, sharp, canvas

## ğŸ“¦ Installation

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/DeepakSingh0027/Query-Retrieval-System.git
```

### 2ï¸âƒ£ Install dependencies

```bash
npm install
```

### 3ï¸âƒ£ Post-install rebuild (required for sharp & canvas)

```bash
npm rebuild sharp && npm rebuild canvas
```

### 4ï¸âƒ£ Install LibreOffice (Required for libreoffice-convert)

**Ubuntu/Debian**

```bash
sudo apt update
sudo apt install libreoffice
```

**MacOS (Homebrew)**

```bash
brew install --cask libreoffice
```

**Windows**

```bash
-Download from LibreOffice Official Website.:https://www.libreoffice.org/download/download/
-Add LibreOffice's program folder path (e.g., C:\Program Files\LibreOffice\program) to your system PATH.
```

### 5ï¸âƒ£ Environment Variables

Create a .env file in the server directory:
(Note: Already pushed.)

```bash
GITHUB_TOKEN=<your_main_github_api_token>
GITHUB_TOKEN2=<token_2>
GITHUB_TOKEN3=<token_3>
.. up to GITHUB_TOKEN12 if needed
```

### â–¶ï¸ Running the Server

```bash
cd server
node server.js
```

### ğŸ“‚ File Structure

```bash
server/
â”‚â”€â”€ server.js # Main entry point
â”‚â”€â”€ controllers/
â”‚ â””â”€â”€ hackrxController.js # Main processing workflow
â”‚â”€â”€ utils/
â”‚ â”œâ”€â”€ chunkText.js # Chunking logic
â”‚ â”œâ”€â”€ semanticSearch.js # Embedding & similarity search
â”‚ â”œâ”€â”€ queryModel.js # LLM integration
â”‚ â””â”€â”€ functions/
â”‚ â”œâ”€â”€ extractor.js # File handling & extraction
â”‚ â””â”€â”€ extractor2.js # PDF conversion fallback
â”‚â”€â”€ extractorsUtils/
â”‚ â”œâ”€â”€ pptExtract.js
â”‚ â”œâ”€â”€ docxExtract.js
â”‚ â””â”€â”€ xlExtract.js
â”‚â”€â”€ package.json
â”‚â”€â”€ .env
(Note: There are more files that supports/helps the main workflow that is not mentioned here.)
```

### ğŸ“œ Example Workflow

```bash
1 - User sends API request with:
documents: array of URLs or file paths
questions: array of strings
2 - System:
Detects file type â†’ extracts text (with OCR if needed)
Splits text into semantic chunks
Embeds chunks into vectors
Finds top relevant chunks per question
Sends context to LLM
LLM returns JSON-formatted answers
All answers were merged and send back with JSON response.
```
